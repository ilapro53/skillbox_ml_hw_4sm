{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90H1_YdZMMbo"
      },
      "source": [
        "### Домашняя работа\n",
        "\n",
        "**Задание среднего уровня** Примените градиентный спуск к задаче прогнозирования цен на недвижимость в Бостоне. Какого качества на валидации удалось достичь по r2-score? Сколько итераций  понадобилось?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q8EbVXRMMbp"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.spatial import distance\n",
        "%matplotlib inline\n",
        "\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "y = raw_df.values[1::2, 2]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_regressor = SGDRegressor(learning_rate='constant', eta0=0.0000009, fit_intercept=True, random_state=42)\n",
        "w_current, epsilon = np.random.random(13), 0.00002\n",
        "weight_evolution, r2_evolution = [], [] # изменения весов и ошибка на валидации\n",
        "\n",
        "for step in list(range(100000)):\n",
        "    sgd_regressor = sgd_regressor.partial_fit(X_train, y_train)\n",
        "    weight_evolution.append(distance.euclidean(w_current, sgd_regressor.coef_))\n",
        "\n",
        "    if weight_evolution[-1] < epsilon:\n",
        "        print(\"Итарации остановлены на шаге {step}. r2-score = {r2:.5f}\".format(\n",
        "            step=step,\n",
        "            r2 = r2_evolution[-1]\n",
        "          )\n",
        "        )\n",
        "        break\n",
        "\n",
        "    r2_evolution.append(r2_score(y_test, sgd_regressor.predict(X_test)))\n",
        "    w_current = sgd_regressor.coef_.copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaehZqmrRZr9",
        "outputId": "00a9df91-0399-4072-9c4e-302951521f2b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Итарации остановлены на шаге 33162. r2-score = 0.62598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZadrTkGLMMbs"
      },
      "source": [
        "Вы можете начать использовать градиентный спуск уже сейчас! Если вы хотите глубже понять механизмы, которые использует этот приём - добро пожаловать в урок 5, где мы поговорим о математике, которая стоит за градиентным спуском и даже реализуем градиентный спуск на языке Python."
      ]
    }
  ]
}